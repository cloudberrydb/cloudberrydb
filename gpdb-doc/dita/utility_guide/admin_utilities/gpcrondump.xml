<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Composite//EN" "ditabase.dtd">
<topic id="topic1">
  <title id="kp142557">gpcrondump</title>
  <body>
    <p>Writes out a database to SQL script files. The script files can be used to restore the
      database using the <codeph><xref href="./gpdbrestore.xml#topic1" type="topic" format="dita"
        /></codeph> utility. The <codeph>gpcrondump</codeph> utility can be called directly or from
      a <codeph>crontab</codeph> entry.</p>
    <note>This utility is deprecated and will not be supported after the end of Greenplum Database
      5.x Support Life.</note>
    <section id="section2">
      <title>Synopsis</title>
      <codeblock><b>gpcrondump</b> <b>-x</b> <varname>database_name</varname> 
   [<b>-s</b> <varname>schema</varname> | <b>-S</b> <varname>schema</varname> | <b>-t</b> <varname>schema.table</varname> | <b>-T</b> <varname>schema.table</varname>] 
   [<b>--table-file</b>=<varname>filename</varname> | <b>--exclude-table-file</b>=<varname>filename</varname>] 
   [<b>--schema-file</b>=<varname>filename</varname> | <b>--exclude-schema-file</b>=<varname>filename</varname>]
   [<b>--dump-stats</b>] 
   [<b>-u</b> <varname>backup_directory</varname>] [<b>-R</b> <varname>post_dump_script</varname>] [<b>--incremental</b>] 
   [<b>-K</b> <varname>timestamp</varname> [<b>--list-backup-files</b>] ]
   [<b>--prefix</b> <varname>prefix_string</varname> [<b>--list-filter-tables</b>]
   [<b>-c</b> [<b>--cleanup-date</b> <varname>yyyymmdd</varname> | <b>--cleanup-total</b> <varname>n</varname>] ]
   [<b>-z</b>] [<b>-r</b>] 
   [<b>-f</b> <varname>free_space_percent</varname>] [<b>-b</b>] [<b>-h</b>] [<b>-H</b>] [<b>-j</b> | <b>-k</b>] [<b>-g</b>] [<b>-G</b>] [<b>-C</b>] 
   [<b>-d</b> <varname>master_data_directory</varname>] [<b>-B</b> <varname>parallel_processes</varname>] [<b>-a</b>] [<b>-q</b>]
   [<b>-y</b> <varname>reportfile</varname>] [<b>-l</b> <varname>logfile_directory</varname>]
   [<b>--email-file</b> <varname>path_to_file</varname>] [<b>-v</b>]
   { [<b>-E</b> <varname>encoding</varname>] [<b>--inserts</b> | <b>--column-inserts</b>] [<b>--oids</b>] 
     [<b>--no-owner</b> | <b>--use-set-session-authorization</b>] [<b>--no-privileges</b>] 
     [<b>--rsyncable</b>]
     { [<b>--ddboost</b> [<b>--replicate --max-streams</b> <varname>max_IO_streams</varname>]
     [<b>--ddboost-skip-ping</b>] [<b>--ddboost-storage-unit</b>=<varname>unit-ID</varname>]] } | 
     { [<b>--netbackup-service-host</b> <varname>netbackup_server</varname>
     <b>--netbackup-policy</b> <varname>netbackup_policy</varname>
     <b>--netbackup-schedule</b> <varname>netbackup_schedule</varname> [<b>--netbackup-block-size</b> <varname>size</varname>] ]
     [<b>--netbackup-keyword</b> <varname>keyword</varname>] ] } }

<b>gpcrondump</b> <b>--ddboost-host</b> <varname>ddboost_hostname</varname>
   [<b>--ddboost-host</b> <varname>ddboost_hostname</varname> ... ]
   <b>--ddboost-user</b> <varname>ddboost_user</varname> <b>--ddboost-backupdir</b> <varname>backup_directory</varname> 
   [<b>--ddboost-remote]</b> [<b>--ddboost-skip-ping</b>]
   [<b>--ddboost-storage-unit</b>=<varname>unit-ID</varname>] 

<b>gpcrondump</b> <b>--ddboost-show-config</b> [<b>--remote</b>]

<b>gpcrondump</b> <b>--ddboost-config-remove</b>

<b>gpcrondump</b> <b>-o</b> [<b>--cleanup-date</b> <varname>yyyymmdd</varname> | <b>--cleanup-total</b> <varname>n</varname>] 

<b>gpcrondump</b> <b>-?</b> 

<b>gpcrondump</b> <b>--version</b></codeblock>
    </section>
    <section id="section3">
      <title>Description</title>
      <p>The <codeph>gpcrondump</codeph> utility dumps the contents of a database into SQL script
        files, which can then be used to restore the database schema and user data at a later time
        using <codeph>gpdbrestore</codeph>. During a dump operation, users will still have full
        access to the database.</p>
      <p>By default, dump files are created in their respective master and segment data directories
        in a directory named <codeph>db_dumps/<varname>YYYYMMDD</varname></codeph>. The data dump
        files are compressed by default using <codeph>gzip</codeph>.</p>
      <p>The utility backs up the database-level settings for the server configuration parameters
          <codeph>gp_default_storage_options</codeph>, <codeph>optimizer</codeph>, and
          <codeph>search_path</codeph>. The settings are restored when you restore the database with
        the <codeph>gpdbrestore</codeph> utility and specify the <codeph>-e</codeph> option to
        create an empty target database before performing a restore operation.</p>
      <p>If you specify an option to back up schemas, such as <codeph>-s</codeph>, or
          <codeph>-S</codeph>, all procedural languages that are defined in the database are also
        backed up even though they are not schema specific. The languages are backed up to support
        any functions that might be backed up. External items such as shared libraries that are used
        by a language are not backed up. Also, languages are not backed up if you specify an option
        to back up only tables, such as <codeph>-t</codeph>, <codeph>-T</codeph>. </p>
      <p>After a backup operation completes, the utility checks the <codeph>gpcrondump</codeph>
        status file for SQL execution errors and displays a warning if an error is found. The
        default location of the backup status files are in the
            <codeph>db_dumps/<varname>date</varname>/</codeph> directory.</p>
      <p>If you specify an option that includes or excludes tables or schemas, such as
          <codeph>-t</codeph>, <codeph>-T</codeph>, <codeph>-s</codeph>, or <codeph>-S</codeph>, the
        schema qualified names of the tables that are backed up are listed in the file
            <codeph>gp_dump_<varname>timestamp</varname>_table</codeph>. The file is stored in the
        backup directory of the master segment. </p>
      <p><codeph>gpcrondump</codeph> allows you to schedule routine backups of a Greenplum database
        using <codeph>cron</codeph> (a scheduling utility for UNIX operating systems). Cron jobs
        that call <codeph>gpcrondump</codeph> should be scheduled on the master host.</p>
      <note type="warning">Backing up a database with <codeph>gpcrondump</codeph> while
        simultaneously running <codeph>ALTER TABLE</codeph> might cause <codeph>gpcrondump</codeph>
        to fail.<p>Backing up a database with <codeph>gpcrondump</codeph> while simultaneously
          running DDL commands might cause issues with locks. You might see either the DDL command
          or <codeph>gpcrondump</codeph> waiting to acquire locks.</p></note>
    </section>
    <section><b>About Database, Schema, and Table Names</b>
      <p>You can specify names of databases, schemas, and tables that contain these special
        characters. </p><p>
        <codeph>" ' ` ~ # $ % ^ &amp; * ( ) _ - + [ ] { } > &lt; \ | ; : / ?</codeph> and the space
          character.<note>The characters <codeph>!</codeph>, comma (<codeph>,</codeph>), and period
            (<codeph>.</codeph>) are not supported. Also, the tab (<codeph>\t</codeph>) and newline
            (<codeph>\n</codeph>) characters are not supported.</note></p><p>When the name contains
        special characters and is specified on the command line, the name must be enclosed in double
        quotes (<codeph>"</codeph>). Double quotes are optional for names that do not contain
        special characters. For example, either use of quotes is valid on the command line
          <codeph>"my#1schema".mytable</codeph> or <codeph>"my#1schema"."mytable"</codeph>. Within
        the name, these special characters must be escaped with a backslash (<codeph>\</codeph>) :
          <codeph>" ` $ \</codeph> .</p><p>When the name is specified in an input file, the name
        must <i>not</i> be enclosed in double quotes. Special characters do not require escaping.
      </p></section>
    <section>
      <title>Backup Filenames</title>
      <p>The utility creates backup files with this file name format.</p>
      <p><codeblock><varname>prefix_</varname>gp_dump_<varname>content</varname>_<varname>dbid</varname>_<varname>timestamp</varname></codeblock>The
          <codeph>content</codeph> and <codeph>dbid</codeph> are identifiers for the Greenplum
        Database segment instances that are assigned by Greenplum Database. For information about
        the identifiers, see the Greenplum Database system catalog table
          <i>gp_segment_configuration</i> in the <cite>Greenplum Database Reference Guide</cite>.
      </p>
    </section>
    <section id="ddboost"><b>Using Data Domain Boost</b><p>The <codeph>gpcrondump</codeph> utility
        is used to schedule Data Domain Boost (DD Boost) backup operations. The utility is also used
        to set, change, or remove one-time credentials and storage unit ID for DD Boost. The
          <codeph>gpcrondump</codeph>, <codeph>gpdbrestore</codeph>, and <codeph>gpmfr</codeph>
        utilities use the DD Boost credentials to access Data Domain systems. DD Boost information
        is stored in these files.<ul id="ul_o1w_rpt_xv">
          <li><codeph>DDBOOST_CONFIG</codeph> is used by <codeph>gpdbrestore</codeph> and
              <codeph>gpcrondump</codeph> for backup and restore operations with the Data Domain
            system. The <codeph>gpdbrestore</codeph> utility creates or updates the file when you
            specify Data Domain information with the <codeph>--ddboost-host</codeph> option. </li>
          <li><codeph>DDBOOST_MFR_CONFIG</codeph> is used by <codeph>gpmfr</codeph> for remote
            replication operations with the remote Data Domain system. The
              <codeph>gpdbrestore</codeph> utility creates or updates the file when you specify Data
            Domain information with the <codeph>--ddboost-host</codeph> option and the
              <codeph>--ddboost-remote</codeph> option. </li>
        </ul></p><p>The configuration files are created in the current user
          (<codeph>gpadmin</codeph>) home directory on the Greenplum Database master and segment
        hosts. The path and file name cannot be changed. </p><p>When you use DD Boost to perform a
        backup operation, the operation uses a storage unit on a Data Domain system. You can specify
        the storage unit ID when you perform these operations:</p><ul id="ul_dvd_kg5_xv">
        <li>When you set the DD Boost credentials with the <codeph>--ddboost-host</codeph> option.
          If you specify the <codeph>--ddboost-storage-unit</codeph> option, the storage unit ID is
          written to the Greenplum Database DD Boost configuration file
            <codeph>DDBOOST_CONFIG</codeph>. If the storage unit ID is not specified, the default
          value is <codeph>GPDB</codeph>.</li>
        <li>When you perform a backup operation with the <codeph>--ddboost</codeph> option. When you
          specify the <codeph>--ddboost-storage-unit</codeph> option, the utility uses the specified
          Data Domain storage unit for the operation. The value in the configuration file is not
          changed.</li>
      </ul><p>When performing a full backup operation (not an incremental backup), the storage unit
        is created on the Data Domain system if it does not exist. </p><p>A storage unit is not
        created if these <codeph>gpcrondump</codeph> options are specified:
          <codeph>--incremental</codeph>, <codeph>--list-backup-file</codeph>,
          <codeph>--list-filter-tables</codeph>, <codeph>-o</codeph>, or
          <codeph>--ddboost-config-remove</codeph>. </p><p>Use the <codeph>gpcrondump</codeph>
        option <codeph>--ddboost-show-config</codeph> to display the current DD Boost configuration
        information from the master configuration file. Specify the <codeph>--remote</codeph> option
        to display the configuration information for the remote Data Domain system.</p><p>For
        information about using DD Boost and Data Domain systems with Greenplum Database, see
        "Backing Up and Restoring Databases" in the <cite>Greenplum Database Administrator
          Guide</cite>.</p></section>
    <section otherprops="pivotal"><b>Using NetBackup</b>
      <p>Veritas NetBackup integration is included with Pivotal Greenplum Database. Greenplum
        Database must be configured to communicate with the Veritas NetBackup master server that is
        used to backup the database. </p><p>When backing up a large amount of data, set the
        NetBackup <codeph>CLIENT_READ_TIMEOUT</codeph> option to a value that is at least twice the
        expected duration of the operation (in seconds). The <codeph>CLIENT_READ_TIMEOUT</codeph>
        default value is <codeph>300</codeph> seconds (5 minutes).</p><p>See the <cite>Greenplum
          Database Administrator Guide</cite> for information on configuring Greenplum Database and
        NetBackup and backing up and restoring with NetBackup. </p></section>
    <section><b>About Return Codes</b>
      <p>The following is a list of the codes that <codeph>gpcrondump</codeph> returns.<ul
          id="ul_hhb_sqp_n4">
          <li><b>0</b> – Dump completed with no problems </li>
          <li><b>1</b> – Dump completed, but one or more warnings were generated</li>
          <li><b>2</b> – Dump failed with a fatal error</li>
        </ul></p></section>
    <section><b>Email Notifications</b>
      <p>To have <codeph>gpcrondump</codeph> send out status email notifications after a back up
        operation completes, you must place a file named <codeph>mail_contacts</codeph> in the home
        directory of the Greenplum superuser (<codeph>gpadmin</codeph>) or in the same directory as
        the <codeph>gpcrondump</codeph> utility (<codeph>$GPHOME/bin</codeph>). This file should
        contain one email address per line. <codeph>gpcrondump</codeph> will issue a warning if it
        cannot locate a <codeph>mail_contacts</codeph> file in either location. If both locations
        have a <codeph>mail_contacts</codeph> file, then the one in <codeph>$HOME</codeph> takes
        precedence. </p><p>You can customize the email Subject and From lines of the email
        notifications that gpcrondump sends after a back up completes for a database. You specify
        the option <codeph>--email-file</codeph> with the location of a YAML file that contains
        email Subject and From lines that <codeph>gpcrondump</codeph> uses. for information about
        the format of the YAML file, see <xref href="#topic1/email_yaml" format="dita"/>.
        </p><note>The UNIX mail utility must be running on Greenplum Database host and must be
        configured to allow the Greenplum superuser (<codeph>gpadmin</codeph>) to send
      email.</note></section>
    <section><b>Limitations</b><p otherprops="pivotal">Dell EMC DD Boost is integrated with Pivotal
        Greenplum Database and requires a DD Boost license. Open source Greenplum Database cannot
        use the DD Boost software, but can back up to a Dell EMC Data Domain system mounted as an
        NFS share on the Greenplum master and segment hosts.</p><p otherprops="pivotal">NetBackup is
        not compatible with DD Boost. Both NetBackup and DD Boost cannot be used in a single back up
        operation.</p><p>For incremental back up sets, a full backup and associated incremental
        backups, the backup set must be on a single device. For example, a backup set must all be on
        a file system. <ph otherprops="pivotal">The backup set cannot have some backups on the local
          file system and others on a Data Domain system or a NetBackup system.</ph></p><p>For
        external tables, the table definition is backed up, however the data is not backed up. For
        leaf child partition of a partitioned table that is a readable external table, the leaf
        child partition data is not backed up. </p></section>
    <section id="section7">
      <title>Options</title>
      <parml>
        <plentry>
          <pt>-a (do not prompt)</pt>
          <pd>Do not prompt the user for confirmation.</pd>
        </plentry>
        <plentry>
          <pt>-b (bypass disk space check)</pt>
          <pd>Bypass disk space check. The default is to check for available disk space, unless
              <codeph>--ddboost</codeph> is specified. When using Data Domain Boost, this option is
            always enabled.<p>
              <note>Bypassing the disk space check generates a warning message. With a warning
                message, the return code for <codeph>gpcrondump</codeph> is <codeph>1</codeph> if
                the dump is successful. (If the dump fails, the return code is <codeph>2</codeph>,
                in all cases.)</note>
            </p></pd>
        </plentry>
        <plentry>
          <pt>-B <varname>parallel_processes</varname></pt>
          <pd>The number of segments to check in parallel for pre/post-dump validation. If not
            specified, the utility will start up to 60 parallel processes depending on how many
            segment instances it needs to dump.</pd>
        </plentry>
        <plentry>
          <pt>-c (clear old dump files first)</pt>
          <pd>Specify this option to delete old backups before performing a back up. In the
              <codeph>db_dumps</codeph> directory, the directory where the name is the oldest date
            is deleted. If the directory name is the current date, the directory is not deleted. The
            default is to not delete old backup files. </pd>
          <pd>The deleted directory might contain files from one or more backups.<p>
              <note type="warning">Before using this option, ensure that incremental backups
                required to perform the restore are not deleted. The <codeph>gpdbrestore</codeph>
                utility option <codeph>--list-backup</codeph> lists the backup sets required to
                perform a backup.</note>
            </p></pd>
          <pd>If <codeph>--ddboost</codeph> is specified, only the old files on Data Domain Boost
            are deleted.</pd>
          <pd>You can specify the option <codeph>--cleanup-date</codeph> or
              <codeph>--cleanup-total</codeph> to specify backup sets to delete. </pd>
          <pd>This option is not supported with the <codeph>-u</codeph> option. </pd>
        </plentry>
        <plentry>
          <pt>-C (clean catalog before restore)</pt>
          <pd>Clean out the catalog schema prior to restoring database objects.
              <codeph>gpcrondump</codeph> adds the <codeph>DROP</codeph> command to the SQL script
            files when creating the backup files. When the script files are used by the
              <codeph>gpdbrestore</codeph> utility to restore database objects, the
              <codeph>DROP</codeph> commands remove existing database objects before restoring them. </pd>
          <pd>If <codeph>--incremental</codeph> is specified and the files are on NFS storage, the
              <codeph>-C</codeph> option is not supported. The database objects are not dropped if
            the <codeph>-C</codeph> option is specified.</pd>
        </plentry>
        <plentry>
          <pt>--cleanup-date=<varname>yyyymmdd</varname></pt>
          <pd>Remove backup sets for the date
              <varname>yyyy</varname>-<varname>mm</varname>-<varname>dd</varname>. The date format
            is <varname>yyyymmdd</varname>. If multiple backup sets were created on the date, all
            the backup sets for that date are deleted. If no backup sets are found,
              <codeph>gpcrondump</codeph> returns a warning message and no backup sets are deleted.
            If the <codeph>-c</codeph> option is specified, the backup process continues.</pd>
          <pd>Valid only with the <codeph>-c</codeph> or <codeph>-o</codeph> option. <note
              type="warning">Before using this option, ensure that incremental backups required to
              perform the restore are not deleted. The <codeph>gpdbrestore</codeph> utility option
                <codeph>--list-backup</codeph> lists the backup sets required to perform a
              backup.</note></pd>
        </plentry>
        <plentry>
          <pt>--cleanup-total=<varname>n</varname></pt>
          <pd>Remove the <varname>n</varname> oldest backup sets based on the backup timestamp.</pd>
          <pd>If there are fewer than <varname>n</varname> backup sets, <codeph>gpcrondump</codeph>
            returns a warning message and no backup sets are deleted. If the <codeph>-c</codeph>
            option is specified, the backup process continues.</pd>
          <pd>Valid only with the <codeph>-c</codeph> or <codeph>-o</codeph> option. <note
              type="warning">Before using this option, ensure that incremental backups required to
              perform the restore are not deleted. The <codeph>gpdbrestore</codeph> utility option
                <codeph>--list-backup</codeph> lists the backup sets required to perform a
              backup.</note></pd>
        </plentry>
        <plentry>
          <pt>--column-inserts</pt>
          <pd>Dump data as <codeph>INSERT</codeph> commands with column names.</pd>
          <pd>If <codeph>--incremental</codeph> is specified, this option is not supported.</pd>
        </plentry>
        <plentry>
          <pt>-d <varname>master_data_directory</varname></pt>
          <pd>The master host data directory. If not specified, the value set for
              <codeph>$MASTER_DATA_DIRECTORY</codeph> will be used.</pd>
        </plentry>
        <plentry>
          <pt>--ddboost [--replicate --max-streams <varname>max_IO_streams</varname> ]
            [--ddboost-skip-ping] </pt>
          <pd>Use Data Domain Boost for this backup. Before using Data Domain Boost, set up the Data
            Domain Boost credential with the <codeph>--ddboost-host </codeph>option. Also, see <xref
              href="#topic1/ddboost" format="dita">Using Data Domain Boost</xref>.<p>If
                <codeph>--ddboost</codeph> is specified, the <codeph>-z</codeph> option
              (uncompressed) is recommended. </p><p>Backup compression (turned on by default) should
              be turned off with the <codeph>-z</codeph> option. Data Domain Boost will deduplicate
              and compress the backup data before sending it to the Data Domain
                system.</p><p><codeph>--replicate
                --max-streams<varname>max_IO_streams</varname></codeph> is optional. If you specify
              this option, <codeph>gpcrondump</codeph> replicates the backup on the remote Data
              Domain server after the backup is complete on the primary Data Domain server.
                <codeph>max_IO_streams</codeph> specifies the maximum number of Data Domain I/O
              streams that can be used when replicating the backup set on the remote Data Domain
              server from the primary Data Domain server. </p><p>You can use <codeph>gpmfr</codeph>
              to replicate a backup if replicating a backup with <codeph>gpcrondump</codeph> takes a
              long time and prevents other backups from occurring. Only one instance of
                <codeph>gpcrondump</codeph> can be running at a time. While
                <codeph>gpcrondump</codeph> is being used to replicate a backup, it cannot be used
              to create a backup.</p><p>You can run a mixed backup that writes to both a local disk
              and Data Domain. If you want to use a backup directory on your local disk other than
              the default, use the <codeph>-u</codeph> option. Mixed backups are not supported with
              incremental backups. For more information about mixed backups and Data Domain Boost,
              see "Backing Up and Restoring Databases" in the <cite>Greenplum Database Administrator
                Guide</cite>.</p><note type="important">Never use the Greenplum Database default
              backup options with Data Domain Boost. </note><p>To maximize Data Domain deduplication
              benefits, retain at least 30 days of backups.</p><note>The <codeph>-b</codeph>,
                <codeph>-c</codeph>, <codeph>-f</codeph>, <codeph>-G</codeph>, <codeph>-g</codeph>,
                <codeph>-R</codeph>, and <codeph>-u</codeph> options change if
                <codeph>--ddboost</codeph> is specified. See the options for details. </note></pd>
          <pd>The DDBoost backup options are not supported if the NetBackup options are specified.
          </pd>
        </plentry>
        <plentry>
          <pt>--ddboost-host <varname>ddboost_hostname</varname> [--ddboost-host
              <varname>ddboost_hostname</varname> ...]</pt>
          <pt>--ddboost-user <varname>ddboost_user</varname> --ddboost-backupdir
              <varname>backup_directory</varname></pt>
          <pt>[--ddboost-remote] [--ddboost-skip-ping]</pt>
          <pd>Sets the Data Domain Boost credentials. Do not combine this options with any other
            gpcrondump options. Do not enter just one part of this option. </pd>
          <pd><varname>ddboost_hostname</varname> is the IP address (or hostname associated to the
            IP) of the host. There is a 30-character limit. If you use two or more network
            connections to connect to the Data Domain system, specify each connection with the
              <codeph>--ddboost-host</codeph> option.</pd>
          <pd><varname>ddboost_user</varname> is the Data Domain Boost user name. There is a
            30-character limit.</pd>
          <pd><varname>backup_directory</varname> is the location for the backup files,
            configuration files, and global objects on the Data Domain system. The location on the
            system is <codeph>GPDB/</codeph><varname>backup_directory</varname>. </pd>
          <pd><codeph>--ddboost-remote</codeph> is optional. It indicates that the configuration
            parameters are for the remote Data Domain system used for backup replication and Data
            Domain Boost managed file replication. Credentials for the remote Data Domain system
            must be configured to use the <codeph>--replicate</codeph> option or the
              <codeph>gpmfr</codeph> management utility.</pd>
          <pd>For example:</pd>
          <pd>
            <codeblock>gpcrondump --ddboost-host 192.0.2.230 --ddboost-user ddboostusername --ddboost-backupdir gp_production</codeblock>
            <note>When setting Data Domain Boost credentials, the
                <codeph>--ddboost-backupdir</codeph> option is ignored if the
                <codeph>--ddboost-remote</codeph> option is specified for a Data Domain system that
              is used for the replication of backups. The <codeph>--ddboost-backupdir</codeph> value
              is for backup operations with a Data Domain system, not for backup replication.
            </note>
          </pd>
          <pd>After running <codeph>gpcrondump</codeph> with these options, the system verifies the
            limits on the host and user names and prompts for the Data Domain Boost password. Enter
            the password when prompted; the password is not echoed on the screen. There is a
            40-character limit on the password that can include lowercase letters (a-z), uppercase
            letters (A-Z), numbers (0-9), and special characters ($, %, #, +, etc.).</pd>
          <pd>The system verifies the password. After the password is verified, the system creates
            encrypted <codeph>DDBOOST_CONFIG</codeph> files in the user's home directory.</pd>
          <pd>In the example, the <codeph>--ddboost-backupdir </codeph>option specifies the backup
            directory <codeph>gp_production</codeph> in the Data Domain Storage Unit GPDB.<note>If
              there is more than one operating system user using Data Domain Boost for backup and
              restore operations, repeat this configuration process for each of those
              users.</note><note type="important">Set up the Data Domain Boost credential before
              running any Data Domain Boost backups with the <codeph>--ddboost</codeph> option,
              described above.</note></pd>
        </plentry>
        <plentry>
          <pt>--ddboost-config-remove</pt>
          <pd>Removes all Data Domain Boost credentials from the master and all segments on the
            system. Do not enter this option with any other <codeph>gpcrondump</codeph> option.</pd>
        </plentry>
        <plentry>
          <pt>--ddboost-show-config [--remote]</pt>
          <pd>Optional. Displays the DD Boost configuration file information for the Data Domain
            server. Specify this option with the <codeph>--remote</codeph> option to display the
            configuration file information for remote Data Domain server. No backup is performed.
          </pd>
        </plentry>
        <plentry>
          <pt>--ddboost-skip-ping</pt>
          <pd>Specify this option to skip the ping of a Data Domain system. When working with a Data
            Domain system, ping is used to ensure that the Data Domain system is reachable. If the
            Data Domain system is configured to block ICMP ping probes, specify this option.</pd>
        </plentry>
        <plentry>
          <pt>--ddboost-storage-unit=<varname>unit-ID</varname></pt>
          <pd>Optional. Specify a valid storage unit name for the Data Domain system that is used
            for backup and restore operations. The default storage unit ID is <codeph>GPDB</codeph>.
            See <xref href="#topic1/ddboost" format="dita">Using Data Domain Boost</xref>.<ul
              id="ul_f4s_krt_xv">
              <li>Specify this option with the <codeph>--ddboost-host</codeph> option to create or
                update the storage unit ID in the DD Boost credentials file. </li>
              <li>Specify this option with the <codeph>--ddboost</codeph> option to override the
                storage unit ID in the DD Boost credentials file when performing a backup
                operation.</li>
            </ul></pd>
          <pd>When performing a full backup operation (not an incremental backup), the storage unit
            is created on the Data Domain system if it does not exist.</pd>
          <pd>A replication operation uses the same storage unit ID on both local and remote Data
            Domain systems. </pd>
        </plentry>
        <plentry>
          <pt>--dump-stats</pt>
          <pd>Specify this option to back up database statistics. The data is written to an SQL file
            and can be restored manually or with <codeph>gpdbrestore</codeph> utility. </pd>
          <pd>The statistics are written in the master data directory to
              <codeph>db_dumps/</codeph><varname>YYYYMMDD</varname><codeph>/<varname>prefix_string_</varname>gp_statistics_-1_1_</codeph><varname>timestamp</varname>. </pd>
          <pd>If this option is specified with options that include or exclude tables or schemas,
            the utility backs up only the statistics for the tables that are backed up.</pd>
        </plentry>
        <plentry>
          <pt>-E <varname>encoding</varname></pt>
          <pd>Character set encoding of dumped data. Defaults to the encoding of the database being
            dumped. See the <i>Greenplum Database Reference Guide</i> for the list of supported
            character sets.</pd>
        </plentry>
        <plentry>
          <pt>-email-file <varname>path_to_file</varname></pt>
          <pd>Specify the fully-qualified location of the YAML file that contains the customized
            Subject and From lines that are used when <codeph>gpcrondump</codeph> sends notification
            emails about a database back up. </pd>
          <pd>For information about the format of the YAML file, see <xref href="#topic1/email_yaml"
              format="dita"/>.</pd>
        </plentry>
        <plentry>
          <pt>-f <varname>free_space_percent</varname></pt>
          <pd>When checking that there is enough free disk space to create the dump files, specifies
            a percentage of free disk space that should remain after the dump completes. The default
            is 10 percent.<p>This is option is not supported if <codeph>--ddboost</codeph> or
                <codeph>--incremental</codeph> is specified.</p></pd>
        </plentry>
        <plentry>
          <pt>-g (copy config files)</pt>
          <pd>Secure a copy of the master and segment configuration files
              <codeph>postgresql.conf</codeph>, <codeph>pg_ident.conf</codeph>, and
              <codeph>pg_hba.conf</codeph>. These configuration files are dumped in the master or
            segment data directory to
              <codeph>db_dumps/</codeph><varname>YYYYMMDD</varname><codeph>/config_files_</codeph><varname>timestamp</varname><codeph>.tar.</codeph></pd>
          <pd>If <codeph>--ddboost</codeph> is specified, the backup is located on the default
            storage unit in the directory specified by <codeph>--ddboost-backupdir</codeph> when the
            Data Domain Boost credentials were set. </pd>
        </plentry>
        <plentry>
          <pt>-G (dump global objects)</pt>
          <pd>Back up database metadata information that is not associated with any particular
            schema or table such as roles and tablespaces. Global objects are dumped in the master
            data directory to
                <codeph>db_dumps/</codeph><varname>YYYYMMDD</varname><codeph>/<varname>prefix_string_</varname>gp_global_-1_1_</codeph><varname>timestamp</varname>. </pd>
          <pd>If <codeph>--ddboost</codeph> is specified, the backup is located on the default
            storage unit in the directory specified by <codeph>--ddboost-backupdir</codeph> when the
            Data Domain Boost credentials were set.</pd>
        </plentry>
        <plentry>
          <pt>-h (record dump details)</pt>
          <pd>Record details of the database dump in database table
              <codeph>public.gpcrondump_history</codeph> in the database supplied via
              <codeph>-x</codeph> option. The <codeph>gpcrondump</codeph> utility will create the
            table if it does not currently exist. The <codeph>public</codeph> schema must exist in
            the database so that <codeph>gpcrondump</codeph> can create the
              <codeph>public.gpcrondump_history</codeph> table. The default is to record the
            database dump details. </pd>
          <pd>This option will be deprecated in a future release.</pd>
        </plentry>
        <plentry>
          <pt>-H (disable recording dump details)</pt>
          <pd>Disable recording details of database dump in database table
              <codeph>public.gpcrondump_history</codeph> in the database supplied via -x option. If
            not specified, the utility will create/update the history table. The <codeph>-H</codeph>
            option cannot be selected with the <codeph>-h</codeph> option.<note>The
                <codeph>gpcrondump</codeph> utility creates the
                <codeph>public.gpcrondump_history</codeph> table by default. If the
                <codeph>public</codeph> schema has been deleted from the database, you must specify
              the <codeph>-H</codeph> option to prevent <codeph>gpcrondump</codeph> from returning
              an error when it attempts to create the table.</note></pd>
        </plentry>
        <plentry>
          <pt>--incremental (backup changes to append-optimized tables)</pt>
          <pd>Adds an incremental backup to a backup set. When performing an incremental backup, the
            complete backup set created prior to the incremental backup must be available. The
            complete backup set includes the following backup files:<ul id="ul_lha_aot_mo">
              <li id="kp142667">The last full backup before the current incremental backup</li>
              <li id="kp142668">All incremental backups created between the time of the full backup
                the current incremental backup</li>
            </ul><p>An incremental backup is similar to a full back up except for append-optimized
              tables, including column-oriented tables. An append-optimized table is backed up only
              if one of the following operations was performed on the table after the last
              backup.</p><pre>ALTER TABLE 
INSERT 
DELETE 
UPDATE 
TRUNCATE 
DROP and then re-create the table</pre><p>For
              partitioned append-optimized tables, only the changed table partitions are backed up.
              </p><p>The <codeph>-u</codeph> option must be used consistently within a backup set
              that includes a full and incremental backups. If you use the <codeph>-u</codeph>
              option with a full backup, you must use the <codeph>-u</codeph> option when you create
              incremental backups that are part of the backup set that includes the full backup.
              </p><p>You can create an incremental backup for a full backup of set of database
              tables. When you create the full backup, specify the <codeph>--prefix</codeph> option
              to identify the backup. To include a set of tables in the full backup, use either the
                <codeph>-t</codeph> option or <codeph>--table-file</codeph> option. To exclude a set
              of tables, use either the <codeph>-T</codeph> option or the
                <codeph>--exclude-table-file</codeph> option. See the description of the option for
              more information on its use. </p><p>To create an incremental backup based on the full
              backup of the set of tables, specify the option -<codeph>-incremental</codeph> and the
                <codeph>--prefix</codeph> option with the string specified when creating the full
              backup. The incremental backup is limited to only the tables in the full backup.
              </p><note type="warning"><codeph>gpcrondump</codeph> does not check for available disk
              space prior to performing an incremental backup. </note><note type="important">An
              incremental back up set, a full backup and associated incremental backups, must be on
              a single device. For example, a the backups in a backup set must all be on a file
              system or must all be on a Data Domain system. </note></pd>
        </plentry>
        <plentry>
          <pt>--inserts</pt>
          <pd>Dump data as <codeph>INSERT</codeph>, rather than <codeph>COPY</codeph> commands.</pd>
          <pd>If <codeph>--incremental</codeph> is specified, this option is not supported.</pd>
        </plentry>
        <plentry>
          <pt>-j (vacuum before dump)</pt>
          <pd>Run <codeph>VACUUM</codeph> before the dump starts.</pd>
        </plentry>
        <plentry>
          <pt>-K <varname>timestamp</varname> [--list-backup-files]</pt>
          <pd>Specify the <codeph>timestamp</codeph> that is used when creating a backup. The
              <varname>timestamp</varname> is 14-digit string that specifies a date and time in the
            format <varname>yyyymmddhhmmss</varname>. The date is used for backup directory name.
            The date and time is used in the backup file names. If <codeph>-K
              </codeph><varname>timestamp</varname> is not specified, a timestamp is generated based
            on the system time. </pd>
          <pd>When adding a backup to set of backups, <codeph>gpcrondump</codeph> returns an error
            if the <codeph>timestamp</codeph> does not specify a date and time that is more recent
            than all other backups in the set. </pd>
          <pd><codeph>--list-backup-files</codeph> is optional. When you specify both this option
            and the <codeph>-K </codeph><codeph>timestamp</codeph> option,
              <codeph>gpcrondump</codeph> does not perform a backup. <codeph>gpcrondump</codeph>
            creates two text files that contain the names of the files that will be created when
              <codeph>gpcrondump</codeph> backs up a Greenplum database. The text files are created
            in the same location as the backup files. </pd>
          <pd>The file names use the <codeph>timestamp</codeph> specified by the
              <codeph>-K </codeph><codeph>timestamp</codeph> option and have the suffix
              <codeph>_pipes</codeph> and <codeph>_regular_files</codeph>. For example: </pd>
          <pd>
            <codeblock>gp_dump_20130514093000_pipes
gp_dump_20130514093000_regular_files</codeblock>
          </pd>
          <pd>The <codeph>_pipes</codeph> file contains a list of file names that be can be created
            as named pipes. When <codeph>gpcrondump</codeph> performs a backup, the backup files
            will generate into the named pipes. The <codeph>_regular_files</codeph> file contains a
            list of backup files that must remain regular files. <codeph>gpcrondump</codeph> and
              <codeph>gpdbrestore</codeph> use the information in the regular files during backup
            and restore operations. To backup a complete set of Greenplum Database backup files, the
            files listed in the <codeph>_regular_files</codeph> file must also be backed up after
            the completion of the backup job.</pd>
          <pd>To use named pipes for a backup, you need to create the named pipes on all the
            Greenplum Database hosts and make them writable before running
              <codeph>gpcrondump</codeph>. </pd>
          <pd>If <codeph>--ddboost</codeph> is specified, <codeph>-K <varname>timestamp</varname>
              [--list-backup-files]</codeph> is not supported.</pd>
        </plentry>
        <plentry>
          <pt>-k (vacuum after dump)</pt>
          <pd>Run <codeph>VACUUM</codeph> after the dump has completed successfully.</pd>
        </plentry>
        <plentry>
          <pt>-l <varname>logfile_directory</varname></pt>
          <pd>The directory to write the log file. Defaults to <codeph>~/gpAdminLogs</codeph>.</pd>
        </plentry>
        <plentry>
          <pt>--netbackup-block-size <varname>size</varname></pt>
          <pd>Specify the block size, in bytes, of data being transferred to the Veritas NetBackup
            server. The default is 512 bytes.</pd>
          <pd>NetBackup options are not supported if DDBoost backup options are specified.</pd>
        </plentry>
        <plentry>
          <pt>--netbackup-keyword <varname>keyword</varname></pt>
          <pd>Specify a <varname>keyword</varname> for the backup that is transferred to the Veritas
            NetBackup server. NetBackup adds the keyword property and the specified keyword value to
            the NetBackup .img files that are created for the backup.</pd>
          <pd>The maximum length of this parameter is 127 characters.</pd>
          <pd>NetBackup options are not supported if DDBoost backup options are specified.</pd>
        </plentry>
        <plentry>
          <pt>--netbackup-policy <varname>netbackup_policy</varname></pt>
          <pd>The name of the NetBackup policy created for backing up Greenplum Database.</pd>
          <pd>NetBackup options are not supported if DDBoost backup options are specified.</pd>
          <pd>The maximum length of this parameter is 127 characters.</pd>
        </plentry>
        <plentry>
          <pt>--netbackup-service-host <varname>netbackup_server</varname></pt>
          <pd>The NetBackup master server that Greenplum Database connects to when backing up to
            NetBackup.</pd>
          <pd>NetBackup options are not supported if DDBoost backup options are specified.</pd>
          <pd>The maximum length of this parameter is 127 characters.</pd>
        </plentry>
        <plentry>
          <pt>--netbackup-schedule <varname>netbackup_schedule</varname></pt>
          <pd>The name of the NetBackup schedule created for backing up Greenplum Database.</pd>
          <pd>NetBackup options are not supported if DDBoost backup options are specified</pd>
          <pd>The maximum length of this parameter is 127 characters.</pd>
        </plentry>
        <plentry>
          <pt>--no-owner</pt>
          <pd>Do not output commands to set object ownership.</pd>
        </plentry>
        <plentry>
          <pt>--no-privileges</pt>
          <pd>Do not output commands to set object privileges
              (<codeph>GRANT</codeph>/<codeph>REVOKE</codeph> commands).</pd>
        </plentry>
        <plentry>
          <pt>-o (clear old dump files only)</pt>
          <pd>Clear out old dump files only, but do not run a dump. This will remove the oldest dump
            directory except the current date's dump directory. All dump sets within that directory
            will be removed.</pd>
          <pd>
            <note type="warning">Before using this option, ensure that incremental backups required
              to perform the restore are not deleted. The <codeph>gpdbrestore</codeph> utility
              option <codeph>--list-backup</codeph> lists the backup sets required to perform a
              backup.</note>
          </pd>
          <pd>If <codeph>--ddboost</codeph> is specified, only the old files on Data Domain Boost
            are deleted.</pd>
          <pd>You can specify the option <codeph>--cleanup-date</codeph> or
              <codeph>--cleanup-total</codeph> to specify backup sets to delete.</pd>
          <pd>If <codeph>--incremental</codeph> is specified, this option is not supported.</pd>
        </plentry>
        <plentry>
          <pt>--oids</pt>
          <pd>Include object identifiers (oid) in dump data.</pd>
          <pd>If <codeph>--incremental</codeph> is specified, this option is not supported.</pd>
        </plentry>
        <plentry>
          <pt>--prefix <varname>prefix_string</varname> [--list-filter-tables]</pt>
          <pd>Prepends <codeph>prefix_string</codeph> followed by an underscore character (_) to the
            names of all the backup files created during a backup. </pd>
          <pd><codeph>--list-filter-tables</codeph> is optional. When you specify both options,
              <codeph>gpcrondump</codeph> does not perform a backup. For the full backup created by
              <codeph>gpcrondump</codeph> that is identified by the <codeph>prefix-string</codeph>,
            the tables that were included or excluded for the backup are listed. You must also
            specify the <codeph>--incremental</codeph> option if you specify the
              <codeph>--list-filter-tables</codeph> option. </pd>
          <pd>If <codeph>--ddboost</codeph> is specified,
              <codeph>--prefix</codeph><varname>prefix_string</varname>
            <codeph>[--list-filter-tables]</codeph> is not supported.</pd>
        </plentry>
        <plentry>
          <pt>-q (no screen output)</pt>
          <pd>Run in quiet mode. Command output is not displayed on the screen, but is still written
            to the log file.</pd>
        </plentry>
        <plentry>
          <pt>-r (rollback on failure)</pt>
          <pd>Rollback the dump files (delete a partial dump) if a failure is detected. The default
            is to not rollback.<note>This option is not supported if <codeph>--ddboost</codeph> is
              specified.</note></pd>
        </plentry>
        <plentry>
          <pt>-R <varname>post_dump_script</varname></pt>
          <pd>The absolute path of a script to run after a successful dump operation. For example,
            you might want a script that moves completed dump files to a backup host. This script
            must reside in the same location on the master and all segment hosts.</pd>
        </plentry>
        <plentry>
          <pt>--rsyncable</pt>
          <pd>Passes the <codeph>--rsyncable</codeph> flag to the <codeph>gzip</codeph> utility to
            synchronize the output occasionally, based on the input during compression. This
            synchronization increases the file size by less than 1% in most cases. When this flag is
            passed, the <codeph>rsync(1)</codeph> program can synchronize compressed files much more
            efficiently. The <codeph>gunzip</codeph> utility cannot differentiate between a
            compressed file created with this option, and one created without it.</pd>
        </plentry>
        <plentry>
          <pt>-s <varname>schema_name</varname></pt>
          <pd>Dump all the tables that are qualified by the specified schema in the database. The
              <codeph>-s</codeph> option can be specified multiple times. System catalog schemas are
            not supported. If you want to specify multiple schemas, you can also use the
              <codeph>--schema-file=</codeph><varname>filename</varname> option in order not to
            exceed the maximum token limit.</pd>
          <pd>Only a set of tables or set of schemas can be specified. For example, the
              <codeph>-s</codeph> option cannot be specified with the <codeph>-t</codeph>
            option.</pd>
          <pd>If <codeph>--incremental</codeph> is specified, this option is not supported.</pd>
        </plentry>
        <plentry>
          <pt>-S <varname>schema_name</varname></pt>
          <pd>A schema name to <i>exclude</i> from the database dump. The <codeph>-S</codeph> option
            can be specified multiple times. If you want to specify multiple schemas, you can also
            use the <codeph>--exclude-schema-file=</codeph><varname>filename</varname> option in
            order not to exceed the maximum token limit.</pd>
          <pd>Only a set of tables or set of schemas can be specified. For example, this option
            cannot be specified with the <codeph>-t</codeph> option.</pd>
          <pd>If <codeph>--incremental</codeph> is specified, this option is not supported.</pd>
        </plentry>
        <plentry>
          <pt>-t <varname>schema.table_name</varname></pt>
          <pd>Dump only the named table in this database. The <codeph>-t</codeph> option can be
            specified multiple times. If you want to specify multiple tables, you can also use the
              <codeph>--table-file=</codeph><varname>filename</varname> option in order not to
            exceed the maximum token limit.</pd>
          <pd>Only a set of tables or set of schemas can be specified. For example, this option
            cannot be specified with the <codeph>-s</codeph> option.</pd>
          <pd>If <codeph>--incremental</codeph> is specified, this option is not supported.</pd>
        </plentry>
        <plentry>
          <pt>-T <varname>schema.table_name</varname></pt>
          <pd>A table name to <i>exclude</i> from the database dump. The <codeph>-T</codeph> option
            can be specified multiple times. If you want to specify multiple tables, you can also
            use the <codeph>--exclude-table-file=</codeph><varname>filename</varname> option in
            order not to exceed the maximum token limit.</pd>
          <pd>Only a set of tables or set of schemas can be specified. For example, this option
            cannot be specified with the <codeph>-s</codeph> option.</pd>
          <pd>If <codeph>--incremental</codeph> is specified, this option is not supported.</pd>
        </plentry>
        <plentry>
          <pt>--exclude-schema-file=<varname>filename</varname></pt>
          <pd> Excludes all the tables that are qualified by the specified schemas listed in the
              <varname>filename</varname> from the database dump. The file
              <varname>filename</varname> contains any number of schemas, listed one per line. </pd>
          <pd>Only a set of tables or set of schemas can be specified. For example, this option
            cannot be specified with the <codeph>-t</codeph> option.</pd>
          <pd>If <codeph>--incremental</codeph> is specified, this option is not supported.</pd>
        </plentry>
        <plentry>
          <pt>--exclude-table-file=<varname>filename</varname></pt>
          <pd> Excludes all tables listed in the <varname>filename</varname> from the database dump.
            The file <varname>filename</varname> contains any number of tables, listed one per line. </pd>
          <pd>Only a set of tables or set of schemas can be specified. For example, this cannot be
            specified with the <codeph>-s</codeph> option.</pd>
          <pd>If <codeph>--incremental</codeph> is specified, this option is not supported.</pd>
        </plentry>
        <plentry>
          <pt>--schema-file=<varname>filename</varname></pt>
          <pd>Dumps only the tables that are qualified by the schemas listed in the
              <varname>filename</varname>. The file <varname>filename</varname> contains any number
            of schemas, listed one per line. </pd>
          <pd>Only a set of tables or set of schemas can be specified. For example, this option
            cannot be specified with the <codeph>-t</codeph> option.</pd>
          <pd>If <codeph>--incremental</codeph> is specified, this option is not supported.</pd>
        </plentry>
        <plentry>
          <pt>--table-file=<varname>filename</varname></pt>
          <pd>Dumps only the tables listed in the <varname>filename</varname>. The file
              <varname>filename</varname> contains any number of tables, listed one per line.</pd>
          <pd>Only a set of tables or set of schemas can be specified. For example, this cannot be
            specified with the <codeph>-s</codeph> option.</pd>
          <pd>If <codeph>--incremental</codeph> is specified, this option is not supported.</pd>
        </plentry>
        <plentry>
          <pt>-u <varname>backup_directory</varname></pt>
          <pd>Specifies the absolute path where the backup files will be placed on each host. If the
            path does not exist, it will be created, if possible. If not specified, defaults to the
            data directory of each instance to be backed up. Using this option may be desirable if
            each segment host has multiple segment instances as it will create the dump files in a
            centralized location rather than the segment data directories.</pd>
          <pd>
            <note>This option is not supported if <codeph>--ddboost</codeph> is specified.</note>
          </pd>
        </plentry>
        <plentry>
          <pt>--use-set-session-authorization</pt>
          <pd>Use <codeph>SET SESSION AUTHORIZATION</codeph> commands instead of <codeph>ALTER
              OWNER</codeph> commands to set object ownership.</pd>
        </plentry>
        <plentry>
          <pt>-v | --verbose</pt>
          <pd>Specifies verbose mode.</pd>
        </plentry>
        <plentry>
          <pt>--version (show utility version)</pt>
          <pd>Displays the version of this utility.</pd>
        </plentry>
        <plentry>
          <pt>-x <varname>database_name</varname></pt>
          <pd>Required. The name of the Greenplum database to dump. </pd>
        </plentry>
        <plentry>
          <pt>-y <varname>reportfile</varname></pt>
          <pd>This option is deprecated and will be removed in a future release. If specified, a
            warning message is returned stating that the <codeph>-y</codeph> option is
            deprecated.</pd>
          <pd>Specifies the full path name where a copy of the backup job log file is placed on the
            master host. The job log file is created in the master data directory or if running
            remotely, the current working directory. </pd>
        </plentry>
        <plentry>
          <pt>-z (no compression)</pt>
          <pd>Do not use compression. Default is to compress the dump files using
              <codeph>gzip</codeph>.</pd>
          <pd>Use this option (<codeph>-z</codeph>) for NFS and Data Domain Boost backups.</pd>
        </plentry>
        <plentry>
          <pt>-? (help)</pt>
          <pd>Displays the online help.</pd>
        </plentry>
      </parml>
    </section>
    <section id="email_yaml">
      <title>File Format for Customized Emails</title>
      <p>You can configure <codeph>gpcrondump</codeph> to send an email notification after a back up
        operation completes for a database. To customize the From and Subject lines of the email
        that are sent for a database, you create a YAML file and specify the location of the file
        with the option <codeph>--email-file</codeph>. In the YAML file, you can specify a different
        From and Subject line for each database that <codeph>gpcrondump</codeph> backs up. This is
        the format of the YAML file to specify a custom From and Subject line for a database: </p>
      <codeblock>
EMAIL_DETAILS:
    -
        DBNAME: <varname>database_name</varname>
        FROM: <varname>from_user</varname>
        SUBJECT: <varname>subject_text</varname>
</codeblock>
      <p>When email notification is configured for gpcrondump, the <varname>from_user</varname> and
        the <varname>subject_text</varname> are the strings that <codeph>gpcrondump</codeph> uses in
        the email notification after completing the back up for
        <varname>database_name</varname>.</p>
      <p>This example YAML file specifies different From and Subject lines for the databases
          <codeph>testdb100</codeph> and <codeph>testdb200</codeph>.</p>
      <codeblock>
EMAIL_DETAILS:
    -
        DBNAME: testdb100
        FROM: RRP_MPE2_1
        SUBJECT: backup completed for Database 'testdb100'
    -
        DBNAME: testdb200
        FROM: Report_from_DCDDEV_host
        SUBJECT: Completed backup for database 'testdb200'</codeblock>
    </section>
    <section id="section8">
      <title>Examples</title>
      <p>Call <codeph>gpcrondump</codeph> directly and dump <codeph>mydatabase</codeph> (and global
        objects):</p>
      <codeblock>gpcrondump -x mydatabase -c -g -G</codeblock>
      <p>A <codeph>crontab</codeph> entry that runs a backup of the <codeph>sales</codeph> database
        (and global objects) nightly at one past midnight:</p>
      <codeblock>01 0 * * * /home/gpadmin/gpdump.sh &gt;&gt; gpdump.log</codeblock>
      <p>The content of dump script gpdump.sh is:</p>
      <codeblock>#!/bin/bash
  export GPHOME=/usr/local/greenplum-db
  export MASTER_DATA_DIRECTORY=/data/gpdb_p1/gp-1
  . $GPHOME/greenplum_path.sh  
  gpcrondump -x sales -c -g -G -a -q </codeblock>
      <p>This example creates two text files, one with the suffix <codeph>_pipes</codeph> and the
        other with <codeph>_regular_files</codeph>. The <codeph>_pipes</codeph> file contain the
        file names that can be named pipes when you backup the Greenplum database mytestdb.</p>
      <codeblock>gpcrondump -x mytestdb -K 20131030140000 --list-backup-files</codeblock>
      <p>To use incremental backup with a set of database tables, you must create a full backup of
        the set of tables and specify the <codeph>--prefix</codeph> option to identify the backup
        set. The following example uses the --table-file option to create a full backup of the set
        of files listed in the file <codeph>user-tables</codeph>. The prefix
          <codeph>user_backup</codeph> identifies the backup set. </p>
      <codeblock>gpcrondump -x mydatabase --table-file=user-tables
  --prefix user_backup</codeblock>
      <p>To create an incremental backup for the full backup created in the previous example,
        specify the <codeph>--incremental</codeph> option and the option <codeph>--prefix
          user_backup</codeph> to identify backup set. This example creates an incremental
        backup.</p>
      <codeblock>gpcrondump -x mydatabase --incremental --prefix user_backup</codeblock>
      <p>This command lists the tables that were included or excluded for the full backup.</p>
      <codeblock>gpcrondump -x mydatabase --incremental --prefix user_backup 
  --list-filter-tables</codeblock>
      <p>This command backs up the database <i>customer</i> and specifies a NetBackup policy and
        schedule that are defined on the NetBackup master server<codeph> nbu_server1</codeph>. A
        block size of 1024 bytes is used to transfer data to the NetBackup server. </p>
      <codeblock>gpcrondump -x customer --netbackup-service-host=nbu_server1
  --netbackup-policy=gpdb_cust --netbackup-schedule=gpdb_backup
  --netbackup-block-size=1024</codeblock>
    </section>
    <section id="section9">
      <title>See Also</title>
      <p>
        <codeph>
          <xref href="./gpdbrestore.xml#topic1" type="topic" format="dita"/>
        </codeph>
      </p>
    </section>
  </body>
</topic>
