CREATE OR REPLACE FUNCTION read_from_s3() RETURNS integer AS
        '$libdir/gps3ext.so', 's3_import' LANGUAGE C STABLE;
CREATE OR REPLACE FUNCTION write_to_s3() RETURNS integer AS
        '$libdir/gps3ext.so', 's3_export' LANGUAGE C STABLE;
CREATE PROTOCOL s3 (
        readfunc = read_from_s3,
        writefunc = write_to_s3
);
DROP EXTERNAL TABLE IF EXISTS s3write_bulk_read;
NOTICE:  table "s3write_bulk_read" does not exist, skipping
DROP EXTERNAL TABLE IF EXISTS s3write_bulk_write;
NOTICE:  table "s3write_bulk_write" does not exist, skipping
CREATE READABLE EXTERNAL TABLE s3write_bulk_read (date text, time text, status bool, sample1 float, sample2 float,
        volume int) LOCATION('s3://s3-us-west-2.amazonaws.com/s3write.pivotal.io/regress/s3write/bulk/ config=/home/gpadmin/s3.conf') FORMAT 'csv';
CREATE WRITABLE EXTERNAL TABLE s3write_bulk_write (date text, time text, status bool, sample1 float, sample2 float,
        volume int) LOCATION('s3://s3-us-west-2.amazonaws.com/s3write.pivotal.io/regress/s3write/bulk/ config=/home/gpadmin/s3.conf') FORMAT 'csv';
SELECT count(*) FROM s3write_bulk_read;
 count 
-------
     0
(1 row)

--     100,000 rows occupy 5.4MB in plain CSV format
--   1,000,000 rows occupy 55MB in plain CSV format
--  10,000,000 rows occupy 559MB in plain CSV format
-- 100,000,000 rows occupy 5.6GB in plain CSV format
INSERT INTO s3write_bulk_write (date, time, status, sample1, sample2, volume)
	SELECT current_date, localtime, (random() > 0.5)::bool, trunc(random()::numeric, 8), trunc(random()::numeric, 8), v
	FROM generate_series(1,100000) as v;
SELECT min(volume), max(volume), count(*) FROM s3write_bulk_read;
 min |  max   | count  
-----+--------+--------
   1 | 100000 | 100000
(1 row)

DROP EXTERNAL TABLE IF EXISTS s3write_bulk_read;
DROP EXTERNAL TABLE IF EXISTS s3write_bulk_write;
DROP PROTOCOL s3;
